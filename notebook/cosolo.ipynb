{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ProjectDescription</th>\n",
       "      <th>ProfileDescription</th>\n",
       "      <th>Preference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We arethe transformation arm of a Fortune 100 ...</td>\n",
       "      <td>Market Research, Employee Fixed TermResume Exa...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>We are a PE firm seeking a junior consulting r...</td>\n",
       "      <td>Director of Market ResearchResume Examples &amp; S...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>We are a mid-market private equity firm lookin...</td>\n",
       "      <td>Market Research Senior ManagerResume Examples ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I am launching a new commercial real estate pl...</td>\n",
       "      <td>Senior Manager, Corporate Market ResearchResum...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>We are a PE-backed consumer products business ...</td>\n",
       "      <td>HBO Director, Market ResearchResume Examples &amp;...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                 ProjectDescription  \\\n",
       "0   1  We arethe transformation arm of a Fortune 100 ...   \n",
       "1   2  We are a PE firm seeking a junior consulting r...   \n",
       "2   3  We are a mid-market private equity firm lookin...   \n",
       "3   4  I am launching a new commercial real estate pl...   \n",
       "4   5  We are a PE-backed consumer products business ...   \n",
       "\n",
       "                                  ProfileDescription Preference  \n",
       "0  Market Research, Employee Fixed TermResume Exa...          N  \n",
       "1  Director of Market ResearchResume Examples & S...          N  \n",
       "2  Market Research Senior ManagerResume Examples ...          N  \n",
       "3  Senior Manager, Corporate Market ResearchResum...          N  \n",
       "4  HBO Director, Market ResearchResume Examples &...          N  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "train = pd.read_csv(\"projects_profile_match.tsv\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3,encoding='latin-1')\n",
    "\n",
    "# create training and testing vars\n",
    "y = train.Preference\n",
    "X = train.drop('Preference', axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train:\n",
      "\n",
      "        ID                                 ProjectDescription  \\\n",
      "960    961  Hi!I'm seeking a business analyst that can hel...   \n",
      "1757  1758  We are looking for a consultant to help us wit...   \n",
      "6323  6324  We are an IT services organization and a plati...   \n",
      "295    296  We are a PE firm that owns a BPO services/soft...   \n",
      "2748  2749  BackgroundOur client's Emerging Innovation Org...   \n",
      "\n",
      "                                     ProfileDescription  \n",
      "960   Market Research, Employee Fixed TermResume Exa...  \n",
      "1757  Sound working knowledge and experience using a...  \n",
      "6323  Senior Manager, Corporate Market ResearchResum...  \n",
      "295   Finance Accounting ManagerResume Examples & Sa...  \n",
      "2748  Gather and analyze massive amounts of informat...  \n",
      "(6848, 3)\n",
      "\n",
      "X_test:\n",
      "\n",
      "        ID                                 ProjectDescription  \\\n",
      "1101  1102  uBiome is a biotechnology company that sequenc...   \n",
      "8267  8268  We are a Mid-Size US based enterprise seeking ...   \n",
      "2605  2606  We are looking for a consultant to help us con...   \n",
      "1318  1319  Professional Engineer, active member of Nation...   \n",
      "3927  3928  Naylor Association Solutions currently has a n...   \n",
      "\n",
      "                                     ProfileDescription  \n",
      "1101  Support the SVP, Talent Development & Strategy...  \n",
      "8267  Structure complex, ambiguous, and potentially ...  \n",
      "2605  Market Research LeadResume Examples & SamplesC...  \n",
      "1318  Supports the assessment, design, and delivery ...  \n",
      "3927  Market Research FellowshipResume Examples & Sa...  \n",
      "(1712, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split the data in 80/20 for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)\n",
    "print(\"\\nX_train:\\n\")\n",
    "print(X_train.head())\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"\\nX_test:\\n\")\n",
    "print(X_test.head())\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.shape\n",
    "#train.columns.values\n",
    "#print(train[\"ProjectDescription\"][0])\n",
    "\n",
    "#train.head()\n",
    "\n",
    "#Keep only letters. Remove everything else in the .\n",
    "letters_only = re.sub(\"[^a-zA-Z]\",           # The pattern to search for\n",
    "                      \" \",                   # The pattern to replace it with\n",
    "                      X_train[\"ProjectDescription\"][0])\n",
    "#print(letters_only)\n",
    "lower_case = letters_only.lower()        # Convert to lower case\n",
    "words = lower_case.split()\n",
    "#print(stopwords.words(\"english\"))\n",
    "\n",
    "# Clean up the tex. Remove stop words from \"words\"\n",
    "words = [w for w in words if not w in stopwords.words(\"english\")]\n",
    "#print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def description_to_words( raw_description ):\n",
    "    # Function to convert a raw description to a string of words\n",
    "    # The input is a single string (a raw description), and \n",
    "    # the output is a single string (a preprocessed description)\n",
    "    #\n",
    "   \n",
    "    # 1. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", str(raw_description))\n",
    "    #\n",
    "    # 2. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 3. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 4. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of description based on the dataframe column size\n",
    "num_description = train[\"ProjectDescription\"].size\n",
    "\n",
    "# Initialize an empty list to hold the clean descriptions\n",
    "clean_train_description = []\n",
    "\n",
    "# Loop over each description; create an index i that goes from 0 to the length\n",
    "# of the description list \n",
    "for i in range( 0, num_description ):\n",
    "    # Call our function for each one, and add the result to the list of\n",
    "    # clean reviews\n",
    "    clean_train_description.append( description_to_words( train[\"ProjectDescription\"][i] ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created bag of words\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = 'english',   \\\n",
    "                             max_features = 2000) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(clean_train_description)\n",
    "print(\"Created bag of words\")\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data_features = train_data_features.toarray()\n",
    "\n",
    "vocab = vectorizer.get_feature_names()\n",
    "#print(vocab)\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit( train_data_features, train[\"Preference\"] )\n",
    "\n",
    "#Serialize(Pickle) the forest model so that it can be used in the web front end to predict the values.\n",
    "fileObject = open('forest_pkl','wb')\n",
    "pickle.dump(forest,fileObject)   \n",
    "\n",
    "# here we close the fileObject\n",
    "fileObject.close()\n",
    "\n",
    "#clean_description = description_to_words( train[\"ProjectDescription\"][0] )\n",
    "#print(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1712, 3)\n",
      "        ID                                 ProjectDescription  \\\n",
      "1101  1102  uBiome is a biotechnology company that sequenc...   \n",
      "8267  8268  We are a Mid-Size US based enterprise seeking ...   \n",
      "2605  2606  We are looking for a consultant to help us con...   \n",
      "1318  1319  Professional Engineer, active member of Nation...   \n",
      "3927  3928  Naylor Association Solutions currently has a n...   \n",
      "\n",
      "                                     ProfileDescription  \n",
      "1101  Support the SVP, Talent Development & Strategy...  \n",
      "8267  Structure complex, ambiguous, and potentially ...  \n",
      "2605  Market Research LeadResume Examples & SamplesC...  \n",
      "1318  Supports the assessment, design, and delivery ...  \n",
      "3927  Market Research FellowshipResume Examples & Sa...  \n"
     ]
    }
   ],
   "source": [
    "# we open the file for reading\n",
    "fileObject = open('forest_pkl','rb')  \n",
    "# load the object from the file into var b\n",
    "forest_model = pickle.load(fileObject)\n",
    "\n",
    "# Verify that there are 1712 rows and 3 columns\n",
    "print (X_test.shape)\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1712\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list and append the clean description one by one\n",
    "num_descriptions = len(X_test[\"ProjectDescription\"])\n",
    "print(num_descriptions)\n",
    "clean_test_description = []\n",
    "#Test data is random so we need to get the index to iterate the data\n",
    "key_iter = X_test.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the description...\n",
      "\n",
      "Preference 500 of 1712\n",
      "\n",
      "Preference 1000 of 1712\n",
      "\n",
      "Preference 1500 of 1712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning and parsing the description...\\n\")\n",
    "test_data_key = 0\n",
    "for i in range(0,num_descriptions):\n",
    "    if( (i+1) % 500 == 0 ):\n",
    "        print(\"Preference %d of %d\\n\" % (i+1, num_descriptions))\n",
    "    test_data_key = key_iter[i]\n",
    "    #print(X_test[\"ProjectDescription\"][test_data_key])\n",
    "    clean_description = description_to_words(X_test[\"ProfileDescription\"][test_data_key] )\n",
    "    clean_test_description.append(clean_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id Preference\n",
      "1101  1102          N\n",
      "8267  8268          N\n",
      "2605  2606          N\n",
      "1318  1319          N\n",
      "3927  3928          N\n",
      "3544  3545          N\n",
      "5503  5504          N\n",
      "3407  3408          N\n",
      "5962  5963          N\n",
      "2894  2895          N\n",
      "4821  4822          N\n",
      "5524  5525          N\n",
      "2433  2434          N\n",
      "3464  3465          N\n",
      "7588  7589          N\n",
      "6288  6289          N\n",
      "249    250          N\n",
      "6126  6127          N\n",
      "6092  6093          N\n",
      "1695  1696          N\n",
      "6419  6420          N\n",
      "2289  2290          N\n",
      "5120  5121          N\n",
      "4622  4623          N\n",
      "7531  7532          N\n",
      "6085  6086          N\n",
      "7272  7273          N\n",
      "4389  4390          N\n",
      "3362  3363          N\n",
      "5606  5607          N\n",
      "...    ...        ...\n",
      "2735  2736          N\n",
      "5789  5790          N\n",
      "4265  4266          N\n",
      "7254  7255          N\n",
      "6477  6478          N\n",
      "3840  3841          N\n",
      "57      58          N\n",
      "7159  7160          N\n",
      "7335  7336          N\n",
      "6743  6744          N\n",
      "140    141          N\n",
      "3718  3719          N\n",
      "6041  6042          N\n",
      "5182  5183          N\n",
      "6959  6960          N\n",
      "3752  3753          N\n",
      "5544  5545          N\n",
      "2294  2295          N\n",
      "1823  1824          N\n",
      "5347  5348          N\n",
      "4426  4427          N\n",
      "1320  1321          N\n",
      "3273  3274          N\n",
      "7095  7096          N\n",
      "2239  2240          N\n",
      "4023  4024          N\n",
      "1716  1717          N\n",
      "4778  4779          N\n",
      "904    905          N\n",
      "4719  4720          N\n",
      "\n",
      "[1712 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features = vectorizer.transform(clean_test_description)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "# Use the random forest to make sentiment label predictions\n",
    "result = forest_model.predict(test_data_features)\n",
    "\n",
    "# Copy the results to a pandas dataframe with an \"id\" column and\n",
    "# a \"sentiment\" column\n",
    "output = pd.DataFrame(data={\"id\":X_test[\"ID\"], \"Preference\":result} )\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to write the comma-separated output file\n",
    "output.to_csv( \"Bag_of_Words_model.csv\", index=True, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
